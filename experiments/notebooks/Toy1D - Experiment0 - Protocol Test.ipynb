{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ccc03b5",
   "metadata": {},
   "source": [
    "# World Machine - Toy1D - Experiment 0: Protocol Test\n",
    "\n",
    "In this World Machine experiment, the goal is to make an initial check of whether the model is trainable, using the concept of state discovery, and what the potential impact of the training protocol is, observing the different tasks defined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03dbf7f",
   "metadata": {},
   "source": [
    "## Artifacts \n",
    "\n",
    "This are the artifacts versions related to this experiment.\n",
    "If trying to re-run, please try using this artifacts (mainly the Docker container).\n",
    "\n",
    "Also, observe that the experiment generated data is available.\n",
    "\n",
    "- Code Version: [0.1](https://github.com/H-IAAC/WorldMachine/releases/tag/0.1)\n",
    "- Docker Container Version: [eltoncn/world-machine:0.1\n",
    "](https://hub.docker.com/repository/docker/eltoncn/world-machine/tags/0.1/sha256-f3645e07e3d5863d12f51955aad0b61c38ce6b3be4ec61aac16ea32ce4420f22)\n",
    "- Experiments Results: [![](https://img.shields.io/badge/DOI-10.5281/zenodo.17352548-1082c3?style=for-the-badge)](https://doi.org/10.5281/zenodo.17352548)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e3a5f4",
   "metadata": {},
   "source": [
    "## Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f681a34f",
   "metadata": {},
   "source": [
    "This section briefly presents the newly introduced concepts necessary to understand this experiment. Since this is the first World Machine experiment, the new concepts introduced includes the concept of world model, and the model+protocol itself.\n",
    "\n",
    "A deeper understanding can be obtained through the publications of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603f5fb9",
   "metadata": {},
   "source": [
    "### World Model, Computational World Model, State and Sensorial Data.\n",
    "\n",
    "A world model is the cognitive process that models the world in which the agent is inserted, and allows for predictions.\n",
    "\n",
    "A computational world model is the computational system that makes predictions about the current and future state of a \"world\" based on the sensorial data it receives, but inferring the internal structure of that world.\n",
    "\n",
    "In this process, the \"sensorial data\" is everything that the agent can observe of the external world, and the \"state\" is the internal model the agent creates to make sense and make predictions about this sensorial data. The \"state\" of the world model does not correspond to the real state of the external world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666cd901",
   "metadata": {},
   "source": [
    "### World Machine\n",
    "\n",
    "World Machine is a research project that explores the creation of computational world models.\n",
    "\n",
    "It's also the proposed architecture and protocol of this project. The architecture is a transform-based model, that operates in \"latent world states\", vectors that encode the state of the world model at each instant. At each step, the model predicts the next latent world state using the previous one, conditioned on sensorial data.\n",
    "\n",
    "The core of the model consists of transform blocks. These can be of type \"State\" for blocks that process only the latent state without sensorial data, \"\\<sensorial Data Dimension Name\\>\" for blocks that use a sensorialsensorial dimension, and \"<State Input>\" for blocks that use the state itself at the beginning of the time step as sensorial input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336550e2",
   "metadata": {},
   "source": [
    "### State Discovery\n",
    "\n",
    "To ensure that the \"latent world state\" has its own encoding, as determined by the agent, these states are not provided in advance. However, they are necessary for model inference.\n",
    "\n",
    "To solve this problem, the states are initially randomized. At each training step, the predicted states are saved and used for inference in the next step.\n",
    "\n",
    "This process is called \"state discovery\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4ae44d",
   "metadata": {},
   "source": [
    "### Protocol Steps\n",
    "\n",
    "Several steps of a training protocol were developed for the World Machine training.\n",
    "\n",
    "One of them, \"sensorial masking,\" involves masking sensorial data during training, hiding a random amount of data at each step.\n",
    "\n",
    "Understanding in depth how other steps of the protocol work is not necessary to understand this experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e01b6d",
   "metadata": {},
   "source": [
    "### Evaluation Tasks\n",
    "\n",
    "To assess the capabilities of the World Machine, these tasks were established, to be carried out after training in the validation dataset:\n",
    "\n",
    "- Normal: normal autoregressive model inference\n",
    "- Use state: inference on previously encoded states, without sensorial data.\n",
    "- Prediction: inference of future states, using several previous encoded states, without sensorial data.\n",
    "- Prediction Shallow: inference of future states, using only one previous encoded state, without sensorial data.\n",
    "- Prediction Local: inference of next immediate state, using only one previous encoded state, without sensorial data.\n",
    "- MaskSensorial@x: autoregressive model inference with x% sensorial masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd7db8c",
   "metadata": {},
   "source": [
    "### Toy1D Dataset\n",
    "\n",
    "A synthetic dataset of one-dimensional time series. The series represent a damped physical system, $\\vec{x}_{i+1} = F\\vec{x}_i+\\vec{u}_i$, where:\n",
    "\n",
    "$$\n",
    "F =  \\begin{bmatrix} \n",
    "                1 & \\Delta t & \\frac{\\Delta t^2}{2} \\\\\n",
    "                -0.1 \\Delta t & 1 & \\Delta t \\\\\n",
    "                0 & 0 & 1\n",
    "            \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\\Delta t=1$$\n",
    "\n",
    "The initial $x_0$ of each series is random, and $\\vec{u}_i$ is a random square+impulse wave sum. The data is also clipped to avoid excessively high values Finally, it is also normalized.\n",
    "\n",
    "The sensorial data is the measurement $\\vec{s}_i = \\tanh(H \\vec{x}_i)$, where H is an random 2x2 matrix.\n",
    "\n",
    "In every use, only the position ($\\vec{x}_i^0$) data is used. \n",
    "\n",
    "A sample of the dataset position data:\n",
    "\n",
    "<img src=\"toy1d_experiment0/Toy1D_Sample.png\" max-height=300 />\n",
    "\n",
    "Since the dataset is stochastic, different data can be generated by controlling the seed of the random number generator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684f0830",
   "metadata": {},
   "source": [
    "## Experiment Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b16e0b",
   "metadata": {},
   "source": [
    "### Hypotheses and Goals\n",
    "\n",
    "- H1: The proposed architecture is trainable, using the state discovery method and generating a model capable of coherently predicting sequences\n",
    "- H2: The proposed protocol generates different models, with different performance in the designed tasks\n",
    "- G1: To observe the tasks differences\n",
    "- G2: To observe the quality of the model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87906f2",
   "metadata": {},
   "source": [
    "### Design\n",
    "\n",
    "We train different model configurations. Each configuration may vary in the number of protocol steps used:\n",
    "\n",
    "- Base: only state discovery.\n",
    "- Sensorial Mask: state discovery and sensorial masking.\n",
    "- Complete Protocol: all steps developed so far, state discovery, sensorial masking, sequence breaker, state-check sensorial, fast forward, short time recall, noise adding and local mode.\n",
    "\n",
    "The training loss is the sensorial loss sum of the MSE of the external state $\\vec{x}_0^0$ (also called \"state decoded\") and MSE of the measurement $\\vec{s}_i$.\n",
    "\n",
    "The evaluation metrics are computed with a early saved model in the epoch of minimum validation optimizer loss. But, the training continue until the last epoch for the training metrics generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34611d8",
   "metadata": {},
   "source": [
    "### Randomization\n",
    "\n",
    "At each run, the dataset, model initial parameters and and random values ​​generated and used by each protocol step are randomized.\n",
    "\n",
    "The randomization occurs with a given seed, that is equal for each run in each variation. So \"Base-Run 0\" uses the same random generator as \"Sensorial Mask\". Since the values ​​depend on the order they are generated, we guarantee that at least the datasets generated for each run are the same between variations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52382220",
   "metadata": {},
   "source": [
    "### Sample size\n",
    "\n",
    "For each variation, 15 models are trained in a dataset with 40000 sequences, with 60% for training and 20% for validation (+20% for test, not used)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1534a7f",
   "metadata": {},
   "source": [
    "### Manipulated variables\n",
    "\n",
    "Training parameters:\n",
    "\n",
    "- Batch size: 32\n",
    "- Epochs: 100\n",
    "- Optimizer: AdamW\n",
    "- Learning rate: initial 1E-3\n",
    "  - Cosine Annealing with Warmup scheduler\n",
    "  - T0: 25\n",
    "  - T_mult: 1\n",
    "- Weight Decay: 1E-5\n",
    "\n",
    "Common model parameters:\n",
    "\n",
    "- State size: 128\n",
    "- Positional encoder type: Alibi\n",
    "- Attention heads: 4\n",
    "- Block configuration: Measurement -> Measurement\n",
    "- Sensorial encoders and decoders: point-wise feedforwards\n",
    "\n",
    "Protocol parameters (when used):\n",
    "\n",
    "- State Discovery\n",
    "  - Check input masks: True\n",
    "  - Save state method: replace\n",
    "- Sensorial Masking\n",
    "  - Uniform distribution masking rate between 0 and 1\n",
    "- Sequence Breaker\n",
    "  - N segment: 2\n",
    "  - Fast Forward: True\n",
    "- Short Time Recall\n",
    "  - N (past and future): 5\n",
    "  - Recall stride (past and future): 3\n",
    "  - Dimensions: Measurement and external state\n",
    "- Local Mode\n",
    "  - Chance: 25%\n",
    "- Noise Addition\n",
    "  - State: $\\sim\\mathcal{N}(0, 0.1)$\n",
    "  - Measurement: $\\sim\\mathcal{N}(0, 0.1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3593d95",
   "metadata": {},
   "source": [
    "### Measured variables\n",
    "\n",
    "For every model variation+run:\n",
    "\n",
    "- Training losses\n",
    "  - MSE and SDTW (Soft Dinamic Time Warping) of state decoded and measurement\n",
    "  - Optimizer loss: sum of MSE of state decoded and measurement\n",
    "  - Train and validation losses. But, some protocol steps are not executed in the validation dataset for faster training and better understanding of the model performance. \n",
    "- State decoded evaluation metrics\n",
    "  - MSE and SDTW in defined tasks (normal, use state, prediction, prediction shallow, prediction local)\n",
    "- Inference samples\n",
    "  - In each task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542260fd",
   "metadata": {},
   "source": [
    "### Analysis Plan\n",
    "\n",
    "First, we compute the mean and standard deviation of each loss and metric.\n",
    "\n",
    "The loss trend will be analyzed to verify that the model was adequately trained.\n",
    "\n",
    "The metrics for each variation and task will be compared using mean and deviation to check for variations.\n",
    "\n",
    "The samples will be analyzed qualitatively to check the coherence of the model's inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0659df",
   "metadata": {},
   "source": [
    "## Ethical Considerations\n",
    "\n",
    "Given the nature of this experiment, simulating a synthetic one-dimensional time series, it becomes difficult to understand what impacts this project might have. However, it is important to emphasize the need to analyze, discuss and mitigate potential risks during the development of this project in other experiments, and by analyzing its overall objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393dae66",
   "metadata": {},
   "source": [
    "## Experiment Execution\n",
    "\n",
    "Inside the experiment Docker, or after installing both `world_machine` and `world_machine_experiments`, the experiment can be executed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d9e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m world_machine_experiments.toy1d.experiment0_protocol_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38189a3b",
   "metadata": {},
   "source": [
    "Please note that the experiment may take a few hours to run. The experiment results have been made available and will be presented below.\n",
    "\n",
    "When running the experiment, we used an environment with:\n",
    "- GPU: 1x NVIDIA A100 80GB PCIe\n",
    "- RAM: 1.48 TB\n",
    "- CPU: 2x Intel Xeon Platinum 8358 CPU @ 2.60GHz\n",
    "\n",
    "But, it can possibly run on much less powerful hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4297bf",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The experimental results are briefly presented in this section. Note that a more in-depth analysis can be found in the publications of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3de675",
   "metadata": {},
   "source": [
    "### Train loss\n",
    "<img src=\"toy1d_experiment0/train_history_optimizer_loss.png\" max-height=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1d445e",
   "metadata": {},
   "source": [
    "- O1.1: The loss decreases while using the state discovery technique\n",
    "- O1.2: The use of protocol techniques in training, but not in validation, causes an effect that tends to lead to a false conclusion of underfitting.\n",
    "- O1.3: The complete protocol can cause divergence later in the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6e9f55",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "<img src=\"toy1d_experiment0/metrics_box_plot_mse.png\" max-height=400 /> <img src=\"toy1d_experiment0/metrics_box_plot_0.1sdtw.png\" max-height=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be6d5d8",
   "metadata": {},
   "source": [
    "- O2.1: All models perform better in the normal task\n",
    "- O2.2: The Base model cannot perform other tasks, which involve masking sensorial data, adequately, since it was not trained in the absence of sensorial data.\n",
    "- O2.3: No model just guesses predictions in the absence of sensorial data, since the metrics are always lower than in MaskSensorial@100 (100% masking of sensorial data $\\to$ generates random sequence)\n",
    "- O2.4: Shallow prediction is the most complex task to perform. No model can perform it well.\n",
    "- O2.5: Using the full protocol results in worsening of the Normal and Use State tasks, but also results in significant improvements in Prediction Shallow and Prediction Local.\n",
    "- O2.6: Using multiple pre-coded states (Use State) is considerably easier than using just one state (Local Prediction). The model may be using the trend of the states to predict the sequence.\n",
    "- O2.7: SDTW captures more differences between the variations. But it also generates similar conclusions to the MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd83cb",
   "metadata": {},
   "source": [
    "### Inference Samples\n",
    "\n",
    "<img src=\"toy1d_experiment0/state_decoded_samples.png\" max-height=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8082f7",
   "metadata": {},
   "source": [
    "- O3.1: The sequences that the model predicts are generally coherent, mainly without masking sensory data.\n",
    "- O3.2: Complete protocol can better follow the signal format (e.g. seq 2 and 3), but still fails to predict future sequences correctly.\n",
    "- O3.3: Base model fails to predict coherent sequences in the absence of sensory data\n",
    "- O3.4: High frequency sequence (ex 4) may be more difficult to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e218a6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Linking the observations of the results to the stated hypotheses and objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a04c18",
   "metadata": {},
   "source": [
    "Hyphotese/Goal|Observations|Conclusion\n",
    "-|-|-\n",
    "H1: The proposed architecture is trainable, using the state discovery method and generating a model capable of coherently predicting sequences|O1.1, O1.2, O1.3, O2.3, O3.1|True. The model is trainable and is capable of coherent predict sequences.\n",
    "H2: The proposed protocol generates different models, with different performance in the designed tasks|O1.3, O2.2, O2.5, O3.2, O3.3|True. The protocol steps generate differences in model training and predictions.\n",
    "G1: To observe the tasks differences|O2.1, O2.4, O2.5, O2.6, O3.1, O3.2, O3.4|Tasks have different performance, both objectively and qualitatively, with some being more difficult than others. Sometimes, an improvement in one task can lead to a worsening in another.\n",
    "G2: To observe the quality of the model predictions| O3.1, O3.2, O3.3, O3.4|The model manages to generate coherent predictions, but still fails in several cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
